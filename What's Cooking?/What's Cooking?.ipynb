{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network using Keras for Kaggle's \"What's Cooking\" competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the kaggle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle competitions download -c whats-cooking\n",
    "# !unzip test.json.zip\n",
    "# !unzip train.json.zip\n",
    "# !unzip sample_submission.csv.zip\n",
    "# !rm test.json.zip\n",
    "# !rm train.json.zip\n",
    "# !rm sample_submission.csv.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "\n",
    "# Scientific Python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import MaxPooling1D, Conv1D, Dense, LSTM, Embedding, Flatten, Dropout\n",
    "\n",
    "%matplotlib inline\n",
    "# nltk.download('wordnet')\n",
    "stemmer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train dataset\n",
    "train = pd.read_json('train.json').set_index('id')\n",
    "test = pd.read_json('test.json').set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "train.columns = ['target', 'values']\n",
    "test.columns = ['values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10259</th>\n",
       "      <td>greek</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25693</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20130</th>\n",
       "      <td>filipino</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22213</th>\n",
       "      <td>indian</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13162</th>\n",
       "      <td>indian</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            target                                             values\n",
       "id                                                                   \n",
       "10259        greek  [romaine lettuce, black olives, grape tomatoes...\n",
       "25693  southern_us  [plain flour, ground pepper, salt, tomatoes, g...\n",
       "20130     filipino  [eggs, pepper, salt, mayonaise, cooking oil, g...\n",
       "22213       indian                [water, vegetable oil, wheat, salt]\n",
       "13162       indian  [black pepper, shallots, cornflour, cayenne pe..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6714 unique ingredients\n",
    "ingredients = train['values'].tolist()\n",
    "all_ingredients = [item for sublist in ingredients for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# Categories\n",
    "num_classes = len(train.target.value_counts())\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_str(ls):\n",
    "    new = []\n",
    "    for s in ls:\n",
    "        new.append(s.split(' '))\n",
    "    ing = [item for sublist in new for item in sublist]\n",
    "    return ing\n",
    "\n",
    "def lemmatize(ls):\n",
    "    new = []\n",
    "    for s in ls:\n",
    "        new.append(stemmer.lemmatize(s))\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split on space\n",
    "train['values'] = train['values'].apply(split_str)\n",
    "test['values'] = test['values'].apply(split_str)\n",
    "\n",
    "# Lemmatize\n",
    "train['values'] = train['values'].apply(lemmatize)\n",
    "test['values'] = test['values'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_x(df):\n",
    "    word_list = list(df['values'])\n",
    "    # Tokenize\n",
    "    token = Tokenizer(filters=', ')\n",
    "    token.fit_on_texts(word_list)\n",
    "    encoded_doc = token.texts_to_matrix(df['values'], mode='count')\n",
    "    return encoded_doc, token\n",
    "\n",
    "def preprocess_y(df):\n",
    "    word_list = list(df['target'])\n",
    "    # Tokenize\n",
    "    token = Tokenizer(filters=', ')\n",
    "    token.fit_on_texts(word_list)\n",
    "    encoded_doc = token.texts_to_sequences(df['target'])\n",
    "    encoded_doc = np.array(encoded_doc).reshape(len(encoded_doc), 1)\n",
    "    y = pd.get_dummies(encoded_doc.reshape(-1)).values\n",
    "    return y, token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "X_train, token_x = preprocess_x(train)\n",
    "X_test = token_x.texts_to_matrix(test['values'], mode='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess output\n",
    "y_train, token_y = preprocess_y(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_lenght, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(240, input_shape=(input_lenght,), activation='relu'))\n",
    "    model.add(Dense(120, activation='relu'))\n",
    "    model.add(Dense(60, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 240)               723120    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               28920     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 60)                7260      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                1220      \n",
      "=================================================================\n",
      "Total params: 760,520\n",
      "Trainable params: 760,520\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile\n",
    "model = create_model(X_train.shape[1], num_classes)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33807 samples, validate on 5967 samples\n",
      "Epoch 1/5\n",
      "33807/33807 [==============================] - 16s 484us/step - loss: 1.0101 - acc: 0.7057 - val_loss: 0.7679 - val_acc: 0.7721\n",
      "Epoch 2/5\n",
      "33807/33807 [==============================] - 19s 573us/step - loss: 0.6199 - acc: 0.8098 - val_loss: 0.7070 - val_acc: 0.7967\n",
      "Epoch 3/5\n",
      "33807/33807 [==============================] - 20s 600us/step - loss: 0.4743 - acc: 0.8543 - val_loss: 0.7362 - val_acc: 0.7880\n",
      "Epoch 4/5\n",
      "33807/33807 [==============================] - 19s 562us/step - loss: 0.3568 - acc: 0.8876 - val_loss: 0.8053 - val_acc: 0.7885\n",
      "Epoch 5/5\n",
      "33807/33807 [==============================] - 17s 513us/step - loss: 0.2614 - acc: 0.9171 - val_loss: 0.8673 - val_acc: 0.7888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13498d668>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit\n",
    "model.fit(X_train, y_train, epochs=5, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover classes\n",
    "y_test = model.predict_classes(X_test) + 1\n",
    "y_test = np.array(y_test).reshape(len(y_test), 1)\n",
    "y_test = token_y.sequences_to_texts(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['cuisine'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare output\n",
    "del test['values']\n",
    "test = test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18009</td>\n",
       "      <td>british</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28583</td>\n",
       "      <td>southern_us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41580</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29752</td>\n",
       "      <td>cajun_creole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35687</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id       cuisine\n",
       "0  18009       british\n",
       "1  28583   southern_us\n",
       "2  41580       italian\n",
       "3  29752  cajun_creole\n",
       "4  35687       italian"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "# test.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push to kaggle\n",
    "# !kaggle competitions submit -f test.csv -m neural_network whats-cooking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View submissions\n",
    "# !kaggle competitions submissions whats-cooking"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
